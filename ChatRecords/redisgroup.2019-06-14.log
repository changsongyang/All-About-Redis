2019-06-14 15:38:31,858  佳齐@小米 说: 
请问 codis 报错ERR router is not online。要怎么解决呢？
2019-06-14 15:41:52,711  姜正中@CMBC 说: 
请教个问题 redis哨兵模式下主节点用save “”禁用持久化 从节点是不是就等于一个空数据的节点
2019-06-14 15:43:58,955  陈宝仪@Redis-replicator 说: 
不会
2019-06-14 15:43:59,135  窦锦帅@滴滴 说: 
如果运行在哨兵模式，本身就不存数据啊
2019-06-14 15:44:44,678  窦锦帅@滴滴 说: 
另外主从复制跟开不开启rdb快照也没有关系
2019-06-14 15:44:46,279  陈宝仪@Redis-replicator 说: 
即使禁用持久化，slave使用slaveof连接的时候master也会生成个rdb文件，并把数据发给slave
2019-06-14 15:46:40,495  黄继立@首汽约车 说: 
这个禁用是指日常的持久化，   当你从库发起 SLAVEOF  时候，主库会RDB 一次，将全量数据传到从库应用。
一般，在主从切换，Redis shutdown。 这些关键的点，都会生成RDB。
2019-06-14 15:46:43,212  姜正中@CMBC 说: 
那禁用持久化不是等于没用？怎么都会产生rdb 我该怎么理解呢
2019-06-14 15:48:01,379  陈宝仪@Redis-replicator 说: 
是的[偷笑]所以主从模式，禁用持久化的话，每次redis重启要把rdb文件先删一遍， 要不然就读旧数据进去了
2019-06-14 15:48:13,227  窦锦帅@滴滴 说: 
save是开启定时（按照策略）做快照
2019-06-14 15:48:22,331  窦锦帅@滴滴 说: 
可以设置不保存本地rdb
2019-06-14 15:48:47,034  陈宝仪@Redis-replicator 说: 
如果你是cache那种非持久化的场景就要每次启动先删
2019-06-14 15:49:16,798  陈宝仪@Redis-replicator 说: 
要么使用diskless-sync
2019-06-14 15:50:25,880  洋烊@借贷宝 说: 
@佳齐@小米  router is not online是你proxy报错的么？你先看一眼proxy的zk的元数据里面存的state是什么？
2019-06-14 15:50:40,313  姜正中@CMBC 说: 
好 谢谢详细解答
2019-06-14 15:53:23,533  窦锦帅@滴滴 说: 
@佳齐@小米 你用的codis那个版本？
2019-06-14 15:53:49,674  立龙@盒子科技 说: 
@杨力@喜马拉雅  codis响应慢的问题，解决了吗？ 我遇到过  深受其害  分析过比较长一段时间
2019-06-14 15:55:04,566  立龙@盒子科技 说: 
@杨力@喜马拉雅  codis响应慢的问题，解决了吗？ 我遇到过   分析过比较长一段时间
2019-06-14 15:55:07,624  窦锦帅@滴滴 说: 
有看过
2019-06-14 15:55:49,126  窦锦帅@滴滴 说: 
go的gc也会导致codis-proxy耗时毛刺
2019-06-14 15:56:25,606  鹏程@CMBC 说: 
@姜正中@CMBC 我们总行大多是禁掉了，在master上
2019-06-14 15:56:28,364  杨力@喜马拉雅 说: 
@立龙@盒子科技 还没有解决，还没有确定原因，你们当时是什么原因
2019-06-14 15:57:01,775  立龙@盒子科技 说: 
一般几十ms的延迟，很大可能是机器环境或者网络环境的问题， go的gc 应该只是很偶尔的影响
2019-06-14 15:57:28,543  杨力@喜马拉雅 说: 
@窦锦帅@滴滴 go1.8以后的版本，codis-proxy的gc耗时还是很少的
2019-06-14 15:57:46,350  立龙@盒子科技 说: 
如果持续有大延迟出现的话  我感觉很大可能是环境问题
2019-06-14 15:57:58,633  姜正中@CMBC 说: 
还有一个问题 线上有个11g的一主两从哨兵 有次一个从节点挂了 恢复起来的时候数据全量同步好几次过不来 我设置client output buffer limit 0 0 0仍然不行 后开发现目录下有好几个类似temp得rdb 我删掉后就可以了 虽然恢复了但不知道是不是这个temp rdb的原因 谁能深入解释一下吗
2019-06-14 15:58:13,353  立龙@盒子科技 说: 
是的  我当时排查问题的时候， gc日志也打印了  没啥问题
2019-06-14 15:58:16,374  黄群 说: 
同问
2019-06-14 15:58:34,882  白馨@陌陌 说: 
网络环境具体能说一下吗？
2019-06-14 15:58:37,609  姜正中@CMBC 说: 
@鹏程@CMBC 反正有从节点也不会丢 对吧
2019-06-14 15:59:16,462  鹏程@CMBC 说: 
@黄群 改个群名片？
2019-06-14 15:59:28,539  黄群 说: 
好
2019-06-14 16:00:04,681  杨力@喜马拉雅 说: 
之前遇到过200ms延迟的问题，后来确定是网络丢包导致，但现在遇到的是40ms延迟的问题，40ms延迟网上大多数介绍是没有设置nodelay导致，但是codis-proxy和redis都已经设置了nodelay标记
2019-06-14 16:01:36,503  杨力@喜马拉雅 说: 
@立龙@盒子科技 你们遇到延迟大概是多大，我们现在出max延迟都是40ms，
2019-06-14 16:02:47,231  立龙@盒子科技 说: 
@杨力@喜马拉雅  我这边之前的原因， 有两种情况：
1. server和proxy 分布在不同的物理机，机房新上了一台物理机上有两个server节点，这台物理机和其他机器间的网络有跳线，网络上延迟比较大；
2. 物理机上跑的 slatstack服务， 有个定时任务在疯狂的吃CPU， 影响到上面所有的服务，只是codis比较敏感，最新暴露问题；
2019-06-14 16:03:23,044  立龙@盒子科技 说: 
严重的时候 大面积 read time out
2019-06-14 16:09:25,270  白馨@陌陌 说: 
可以抓包看看 发生40ms的时候 到底redis那端 还是codis那端 出现问题
2019-06-14 16:11:22,711  杨力@喜马拉雅 说: 
@白馨@陌陌 线上问题，抓包比较麻烦，先分析一下原因，如果线下能复现就好了
2019-06-14 16:13:04,963  李剑-携程 说: 
@杨力@喜马拉雅 请在client和server上执行perf看看
2019-06-14 16:13:40,087  杨力@喜马拉雅 说: 
@立龙@盒子科技 你们服务器有专门设置过rto_min这个值吗，通过修改rto_min减少丢包重传的等待时间
2019-06-14 16:13:50,691  立龙@盒子科技 说: 
没有
2019-06-14 16:14:19,852  白馨@陌陌 说: 
抓包这个最简单最直接了 别天天想着改tcp参数 优化什么的
2019-06-14 16:14:37,347  立龙@盒子科技 说: 
关键还是要找出丢包的根本原因
2019-06-14 16:14:44,175  白馨@陌陌 说: 
问题都没有清晰的定位到 改什么tcp 参数
2019-06-14 16:14:55,279  立龙@盒子科技 说: 
改参数意义不大  是的
2019-06-14 16:15:01,426  白馨@陌陌 说: 
谁的问题 是网络的问题 还是物理机器的问题 这个应该先定位到
2019-06-14 16:16:31,887  立龙@盒子科技 说: 
生产环境也好抓包  我们也抓过，业务到proxy  proxy到server， 指定端口抓，  延迟的时候，丢包是肯定的，关键是为什么丢包
2019-06-14 16:17:04,908  xinxinbai@陌陌 说: 
抓包有找到那个40ms的上下文报文吗
2019-06-14 16:18:01,367  杨力@喜马拉雅 说: 
改参数是想看一下能不能解决丢包200ms重传的问题，具体是网络问题还是机器问题我们这边没有权限去查的
2019-06-14 16:18:22,767  立龙@盒子科技 说: 
你的codis集群 有做完整的监控没？  有监控的话  应该能看出很多问题来
2019-06-14 16:19:49,483  杨力@喜马拉雅 说: 
你们用什么监控，我们现在在codis上做了一些QPS，连接数，延迟的一些监控，从监控看到延迟的max值又很多是40ms
2019-06-14 16:21:28,296  立龙@盒子科技 说: 
比如说我们自己做的监控  一眼就看出来 CPU异常
2019-06-14 16:22:07,457  立龙@盒子科技 说: 
而且延迟时间是规律性的， 就比较容易找问题
2019-06-14 16:23:22,432  杨力@喜马拉雅 说: 
你们监控做的挺好，有时间向你请教一下
2019-06-14 16:24:20,393  杨力@喜马拉雅 说: 
你们proxy就是codis原生的codis-proxy吗
2019-06-14 16:25:12,592  立龙@盒子科技 说: 
是啊
2019-06-14 18:50:33,982  黄群@易宝 说: 
rdb_last_bgsave_time_sec:2667
2019-06-14 18:50:49,647  黄群@易宝 说: 
这个耗时这么长，有可能是什么导致的？
2019-06-14 18:54:02,003  鹏程@CMBC 说: 
先看dump时候的io情况
2019-06-14 18:55:25,657  黄群@易宝 说: 
好的
2019-06-14 20:09:25,539  鹏程@CMBC 分享链接:
 #每日分享 「链接」 Redis++: A High Performance In-Memory Database Bas...
https://t.zsxq.com/AuFIMjI
2019-06-14 20:10:37,613  鹏程@CMBC 说: 
IEEE的一篇论文，中科院的人写的
